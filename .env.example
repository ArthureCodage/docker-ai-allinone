# Variables d'environnement pour la configuration Docker AI

# ==============================================
# CONFIGURATION SD-FORGE-NEO
# ==============================================

# Arguments de ligne de commande pour SD-Forge
SDFORGE_ARGS="--listen --port 7860 --xformers --api --enable-insecure-extension-access"

# Port SD-Forge (par défaut: 7860)
SDFORGE_PORT=7860

# Format de sauvegarde des images (jpg, png, webp)
SDFORGE_IMAGE_FORMAT=jpg

# Qualité JPEG (1-100)
SDFORGE_JPEG_QUALITY=95

# Clip Skip (1-12, recommandé: 2)
SDFORGE_CLIP_SKIP=2

# Sampler par défaut
SDFORGE_SAMPLER=Euler

# ==============================================
# CONFIGURATION CIVITAI
# ==============================================

# Clé API Civitai
CIVITAI_API_KEY=150181b2c22ef80bb0c1befb113fd981

# ==============================================
# CONFIGURATION OLLAMA
# ==============================================

# Host Ollama
OLLAMA_HOST=0.0.0.0:11434

# Port Ollama (par défaut: 11434)
OLLAMA_PORT=11434

# Modèle par défaut
OLLAMA_DEFAULT_MODEL=mistral

# ==============================================
# CONFIGURATION OPEN WEBUI
# ==============================================

# Port Open WebUI (par défaut: 8080)
WEBUI_PORT=8080

# Authentification (true/false)
WEBUI_AUTH=false

# Clé secrète (changer en production)
WEBUI_SECRET_KEY=changeme-in-production

# URL de base Ollama
OLLAMA_BASE_URL=http://localhost:11434

# ==============================================
# CONFIGURATION DOCKER
# ==============================================

# Nom du container
CONTAINER_NAME=ai-container

# Nom de l'image
IMAGE_NAME=ai-allinone:latest

# Politique de redémarrage
RESTART_POLICY=unless-stopped

# ==============================================
# CHEMINS DES VOLUMES
# ==============================================

# Chemin de base pour les volumes
VOLUMES_BASE_PATH=~/ai-docker

# Chemin des modèles SD
MODELS_PATH=${VOLUMES_BASE_PATH}/models

# Chemin des outputs SD
OUTPUTS_PATH=${VOLUMES_BASE_PATH}/outputs

# Chemin des données Ollama
OLLAMA_DATA_PATH=${VOLUMES_BASE_PATH}/ollama

# Chemin des données Open WebUI
WEBUI_DATA_PATH=${VOLUMES_BASE_PATH}/open-webui

# ==============================================
# CONFIGURATION GPU
# ==============================================

# Utiliser tous les GPUs disponibles (all ou device ID)
GPU_DEVICES=all

# ==============================================
# CONFIGURATION RÉSEAU
# ==============================================

# Interface réseau (0.0.0.0 pour toutes les interfaces)
LISTEN_ADDRESS=0.0.0.0

# Activer HTTPS (true/false)
ENABLE_HTTPS=false

# Certificat SSL (si HTTPS activé)
SSL_CERT_PATH=/etc/ssl/certs/cert.pem
SSL_KEY_PATH=/etc/ssl/private/key.pem

# ==============================================
# PARAMÈTRES DE PERFORMANCE
# ==============================================

# Mémoire partagée pour Docker (en bytes, e.g., 2g = 2GB)
SHM_SIZE=2g

# Limite mémoire pour le container
MEMORY_LIMIT=16g

# ==============================================
# LOGS
# ==============================================

# Niveau de verbosité des logs (debug, info, warning, error)
LOG_LEVEL=info

# Rotation des logs
LOG_MAX_SIZE=100m
LOG_MAX_FILES=3

# üöÄ Docker AI All-in-One

Environnement Docker unique combinant **SD-Forge-Neo** (g√©n√©ration d'images) et **Ollama + Open WebUI** (g√©n√©ration de texte) dans un seul container.

## üì¶ Contenu

- **SD-Forge-Neo** : Interface de g√©n√©ration d'images Stable Diffusion
- **Civitai Helper** : Extension pour t√©l√©charger des mod√®les depuis Civitai
- **Ollama** : Moteur LLM local
- **Open WebUI** : Interface web moderne pour Ollama

## üéØ Mod√®les Pr√©-Configur√©s

### Checkpoints
- CyberRealistic Pony
- Nova Reality XL

### LoRAs
- Perfect Pussy
- Perfect Eyes XL
- Multiple Girls Group
- POV Group Sex

### Mod√®le LLM
- Mistral-Small-Instruct (via Ollama)

## ‚öôÔ∏è Configuration Minimale Recommand√©e

- **RAM** : 16 GB (32 GB recommand√©)
- **VRAM** : 8 GB minimum (12+ GB pour SDXL)
- **Stockage** : 100 GB minimum (200+ GB recommand√©)
- **GPU** : NVIDIA avec support CUDA (GTX 1080 Ti / RTX 3060+)
- **OS** : Ubuntu 20.04+ avec drivers NVIDIA

## üöÄ Installation Rapide

### Option 1 : Installation Automatique (Recommand√©)

```bash
# 1. Cloner ou t√©l√©charger les fichiers (Dockerfile, install.sh, README.md)
# 2. Rendre le script ex√©cutable et lancer l'installation
chmod +x install.sh
./install.sh
```

**C'est tout !** Le script va :
- Installer Docker (si n√©cessaire)
- Installer NVIDIA Container Toolkit (si n√©cessaire)
- Construire l'image Docker
- D√©marrer le container
- T√©l√©charger tous les mod√®les automatiquement

### Option 2 : Installation Manuelle

```bash
# 1. Construire l'image
docker build -t ai-allinone:latest .

# 2. Cr√©er les volumes persistants
mkdir -p ~/ai-docker/{models,outputs,ollama,open-webui}

# 3. D√©marrer le container
docker run -d \
  --name ai-container \
  --gpus all \
  --restart unless-stopped \
  -p 7860:7860 \
  -p 8080:8080 \
  -p 11434:11434 \
  -v ~/ai-docker/models:/workspace/sd-forge-neo/models \
  -v ~/ai-docker/outputs:/workspace/sd-forge-neo/outputs \
  -v ~/ai-docker/ollama:/root/.ollama \
  -v ~/ai-docker/open-webui:/root/.open-webui \
  ai-allinone:latest
```

## üåê Acc√®s aux Interfaces

Une fois le container d√©marr√© (attendez 5-10 min pour le premier d√©marrage) :

| Service | URL | Description |
|---------|-----|-------------|
| **SD-Forge-Neo** | `http://localhost:7860` | Interface de g√©n√©ration d'images |
| **Open WebUI** | `http://localhost:8080` | Interface de chat avec Ollama |
| **Ollama API** | `http://localhost:11434` | API Ollama (usage interne) |

## üìä V√©rifier le Statut

```bash
# Voir les logs en temps r√©el
docker logs -f ai-container

# V√©rifier que tous les services sont actifs
docker exec ai-container supervisorctl status

# V√©rifier l'utilisation du GPU
nvidia-smi
```

## üîß Gestion du Container

```bash
# Arr√™ter le container
docker stop ai-container

# D√©marrer le container
docker start ai-container

# Red√©marrer le container
docker restart ai-container

# Acc√©der au shell du container
docker exec -it ai-container bash
```

## üì• Ajouter de Nouveaux Mod√®les

### Mod√®les Civitai (Images)

**Option 1 : Via l'interface SD-Forge-Neo**
1. Ouvrir `http://localhost:7860`
2. Aller dans l'onglet **Civitai Helper**
3. Coller l'URL du mod√®le Civitai
4. Cliquer sur "Download"

**Option 2 : Manuellement**
```bash
# Les mod√®les sont dans ~/ai-docker/models/
# Copier vos fichiers .safetensors dans les sous-dossiers appropri√©s :
~/ai-docker/models/Stable-diffusion/  # Pour les checkpoints
~/ai-docker/models/Lora/              # Pour les LoRAs
~/ai-docker/models/VAE/               # Pour les VAE
```

### Mod√®les Ollama (Texte)

**Option 1 : Via Open WebUI**
1. Ouvrir `http://localhost:8080`
2. Menu ‚Üí Admin Panel ‚Üí Settings ‚Üí Models
3. T√©l√©charger depuis Ollama Library ou Hugging Face

**Option 2 : Via CLI**
```bash
# Liste des mod√®les disponibles
docker exec ai-container ollama list

# T√©l√©charger un mod√®le
docker exec ai-container ollama pull llama3.3
docker exec ai-container ollama pull codellama
docker exec ai-container ollama pull mistral

# Supprimer un mod√®le
docker exec ai-container ollama rm <model-name>
```

## üîÑ Mise √† Jour Sans Perte de Donn√©es

Les mod√®les et outputs sont stock√©s dans des volumes Docker persistants. Pour mettre √† jour :

```bash
# 1. Arr√™ter et supprimer le container (les donn√©es restent dans les volumes)
docker stop ai-container
docker rm ai-container

# 2. Reconstruire l'image avec les derni√®res mises √† jour
docker build -t ai-allinone:latest .

# 3. Red√©marrer le container (m√™me commande qu'√† l'installation)
docker run -d \
  --name ai-container \
  --gpus all \
  --restart unless-stopped \
  -p 7860:7860 \
  -p 8080:8080 \
  -p 11434:11434 \
  -v ~/ai-docker/models:/workspace/sd-forge-neo/models \
  -v ~/ai-docker/outputs:/workspace/sd-forge-neo/outputs \
  -v ~/ai-docker/ollama:/root/.ollama \
  -v ~/ai-docker/open-webui:/root/.open-webui \
  ai-allinone:latest
```

**Vos mod√®les et images g√©n√©r√©es seront pr√©serv√©s !**

## üîí Acc√®s S√©curis√© depuis l'Ext√©rieur

> ‚ö†Ô∏è **IMPORTANT** : Ne jamais exposer directement les ports sans authentification !

### Option 1 : Reverse Proxy avec Nginx + SSL

```bash
# Installation de Nginx et Certbot
sudo apt install nginx certbot python3-certbot-nginx

# Configuration Nginx (exemple pour SD-Forge-Neo)
sudo nano /etc/nginx/sites-available/ai-forge

# Contenu :
server {
    listen 80;
    server_name votre-domaine.com;

    location / {
        proxy_pass http://localhost:7860;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# Activer le site et obtenir le certificat SSL
sudo ln -s /etc/nginx/sites-available/ai-forge /etc/nginx/sites-enabled/
sudo certbot --nginx -d votre-domaine.com
sudo systemctl restart nginx
```

### Option 2 : Cloudflare Tunnel (Gratuit, Recommand√©)

```bash
# Installation de cloudflared
wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
sudo dpkg -i cloudflared-linux-amd64.deb

# Authentification
cloudflared tunnel login

# Cr√©ation du tunnel
cloudflared tunnel create ai-tunnel

# Configuration (cr√©er ~/.cloudflared/config.yml)
tunnel: <tunnel-id>
credentials-file: /home/<user>/.cloudflared/<tunnel-id>.json

ingress:
  - hostname: forge.votre-domaine.com
    service: http://localhost:7860
  - hostname: chat.votre-domaine.com
    service: http://localhost:8080
  - service: http_status:404

# D√©marrer le tunnel
cloudflared tunnel run ai-tunnel
```

### Option 3 : VPN (Acc√®s Priv√©)

Installer WireGuard ou OpenVPN pour un acc√®s priv√© s√©curis√©.

## üõ†Ô∏è Configuration SD-Forge-Neo

La configuration par d√©faut inclut :

- **Format de sauvegarde** : JPEG (qualit√© 95%)
- **Clip Skip** : 2
- **Sampler par d√©faut** : Euler
- **Cl√© API Civitai** : Pr√©-configur√©e
- **API activ√©e** : Acc√®s via `http://localhost:7860/docs`

Pour modifier la configuration :
```bash
# √âditer le fichier de config
docker exec -it ai-container nano /workspace/sd-forge-neo/config.json

# Red√©marrer SD-Forge-Neo
docker exec ai-container supervisorctl restart sd-forge-neo
```

## üìÅ Structure des Volumes

```
~/ai-docker/
‚îú‚îÄ‚îÄ models/              # Mod√®les SD-Forge-Neo (checkpoints, LoRAs, VAE)
‚îú‚îÄ‚îÄ outputs/             # Images g√©n√©r√©es
‚îú‚îÄ‚îÄ ollama/              # Mod√®les Ollama
‚îî‚îÄ‚îÄ open-webui/          # Donn√©es Open WebUI (conversations, param√®tres)
```

## ‚ùì D√©pannage

### Le container ne d√©marre pas
```bash
# V√©rifier les logs
docker logs ai-container

# V√©rifier l'√©tat des services
docker exec ai-container supervisorctl status
```

### SD-Forge-Neo ne charge pas
```bash
# Red√©marrer uniquement SD-Forge
docker exec ai-container supervisorctl restart sd-forge-neo

# V√©rifier les logs
docker exec ai-container tail -f /var/log/sd-forge.out.log
```

### Ollama ne r√©pond pas
```bash
# Red√©marrer Ollama
docker exec ai-container supervisorctl restart ollama

# V√©rifier les mod√®les install√©s
docker exec ai-container ollama list
```

### Manque d'espace disque
```bash
# V√©rifier l'espace utilis√©
du -sh ~/ai-docker/*

# Nettoyer les images Docker inutilis√©es
docker system prune -a
```

### Erreur GPU / CUDA
```bash
# V√©rifier que le GPU est accessible
nvidia-smi

# V√©rifier que Docker peut utiliser le GPU
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

## üìù Notes Importantes

- **Premier d√©marrage** : Le t√©l√©chargement des mod√®les peut prendre 10-20 minutes
- **Stockage** : Pr√©voir ~50-70 GB pour les mod√®les pr√©-configur√©s
- **Performances** : Les g√©n√©rations d'images SDXL n√©cessitent au minimum 8 GB de VRAM

## üìö Ressources

- [SD-Forge-Neo GitHub](https://github.com/Haoming02/sd-webui-forge-classic/tree/neo)
- [Civitai Helper](https://github.com/zixaphir/Stable-Diffusion-Webui-Civitai-Helper)
- [Ollama Documentation](https://ollama.com)
- [Open WebUI GitHub](https://github.com/open-webui/open-webui)

## ü§ù Support

Pour toute question ou probl√®me :
1. V√©rifier les logs : `docker logs -f ai-container`
2. Consulter la section D√©pannage ci-dessus
3. V√©rifier les issues GitHub des projets respectifs

---

**Bon codage et bonne cr√©ation ! üé®ü§ñ**

# ğŸ³ Docker AI All-in-One

> Container Docker unique combinant **SD-Forge-Neo** (gÃ©nÃ©ration d'images) et **Ollama + Open WebUI** (gÃ©nÃ©ration de texte avec LLM) pour un dÃ©ploiement simplifiÃ© sur VPS Ubuntu avec GPU NVIDIA.

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![NVIDIA](https://img.shields.io/badge/NVIDIA-GPU-76B900?style=flat&logo=nvidia&logoColor=white)](https://www.nvidia.com/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

---

## ğŸ“‹ Table des MatiÃ¨res

- [AperÃ§u](#-aperÃ§u)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [PrÃ©requis](#-prÃ©requis)
- [Installation Rapide](#-installation-rapide)
- [Documentation](#-documentation)
- [ModÃ¨les Inclus](#-modÃ¨les-inclus)
- [AccÃ¨s aux Interfaces](#-accÃ¨s-aux-interfaces)
- [Gestion](#-gestion)
- [DÃ©pannage](#-dÃ©pannage)
- [Contribution](#-contribution)
- [License](#-license)

---

## ğŸ¯ AperÃ§u

Ce projet fournit un environnement Docker **tout-en-un** pour :
- **GÃ©nÃ©ration d'images** avec Stable Diffusion (SD-Forge-Neo)
- **GÃ©nÃ©ration de texte** avec des LLM locaux (Ollama + Open WebUI)

Tout dans un **seul container Docker**, dÃ©ployable en **une commande**.

### Technologies Incluses

- **[SD-Forge-Neo](https://github.com/Haoming02/sd-webui-forge-classic/tree/neo)** - Interface Stable Diffusion optimisÃ©e
- **[Civitai Helper](https://github.com/zixaphir/Stable-Diffusion-Webui-Civitai-Helper)** - Extension pour tÃ©lÃ©charger des modÃ¨les
- **[Ollama](https://ollama.com)** - Moteur LLM local
- **[Open WebUI](https://github.com/open-webui/open-webui)** - Interface web moderne pour Ollama

---

## âœ¨ FonctionnalitÃ©s

âœ… **Installation en une commande**  
âœ… **Container unique** avec tous les services  
âœ… **GPU NVIDIA** optimisÃ© (CUDA 12.1)  
âœ… **TÃ©lÃ©chargement automatique** des modÃ¨les Civitai  
âœ… **Volumes persistants** pour modÃ¨les et outputs  
âœ… **Configuration prÃ©-paramÃ©trÃ©e** (Euler sampler, Clip Skip 2, JPEG)  
âœ… **Scripts de gestion** interactifs  
âœ… **Support Brev.dev** pour dÃ©ploiement cloud  

---

## ğŸ’» PrÃ©requis

### Configuration Minimale

| Composant | Minimum | RecommandÃ© |
|-----------|---------|------------|
| **RAM** | 16 GB | 32 GB |
| **VRAM** | 8 GB | 12+ GB |
| **Stockage** | 100 GB | 200+ GB |
| **GPU** | NVIDIA GTX 1080 Ti | RTX 3060+ |
| **OS** | Ubuntu 20.04+ | Ubuntu 22.04 |

### Logiciels Requis

- Docker (installÃ© automatiquement par le script)
- NVIDIA Drivers (version rÃ©cente)
- NVIDIA Container Toolkit (installÃ© automatiquement)

---

## ğŸš€ Installation Rapide

### Option 1 : Script Automatique (RecommandÃ©)

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/VOTRE-USERNAME/docker-ai-allinone.git
cd docker-ai-allinone

# Lancer l'installation
chmod +x install.sh
./install.sh
```

**C'est tout !** Le script va :
1. Installer Docker et NVIDIA Container Toolkit (si nÃ©cessaire)
2. Construire l'image Docker
3. DÃ©marrer le container avec tous les services
4. TÃ©lÃ©charger automatiquement les modÃ¨les

### Option 2 : Docker Compose

```bash
git clone https://github.com/VOTRE-USERNAME/docker-ai-allinone.git
cd docker-ai-allinone

docker-compose up -d --build
```

### Option 3 : DÃ©ploiement sur Brev.dev

```bash
# TransfÃ©rer les fichiers sur Brev
scp -r * ubuntu@<brev-instance>:~/ai-docker/

# Sur Brev
cd ~/ai-docker
chmod +x deploy-brev.sh
./deploy-brev.sh
```

Voir **[GUIDE_BREV.md](GUIDE_BREV.md)** pour plus de dÃ©tails.

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| **[README.md](README.md)** | Documentation complÃ¨te et dÃ©taillÃ©e |
| **[QUICKSTART.md](QUICKSTART.md)** | Guide de dÃ©marrage rapide |
| **[GUIDE_BREV.md](GUIDE_BREV.md)** | DÃ©ploiement sur Brev.dev |
| **[NOTES_TECHNIQUES.md](NOTES_TECHNIQUES.md)** | Configurations avancÃ©es |
| **[FICHIERS.md](FICHIERS.md)** | Index de tous les fichiers |

---

## ğŸ¨ ModÃ¨les Inclus

### Checkpoints (Stable Diffusion)
- **CyberRealistic Pony** - GÃ©nÃ©ration rÃ©aliste et stylisÃ©e
- **Nova Reality XL** - Images photorÃ©alistes

### LoRAs
- **Perfect Pussy** - AmÃ©lioration des dÃ©tails anatomiques
- **Perfect Eyes XL** - AmÃ©lioration des yeux
- **Multiple Girls Group** - ScÃ¨nes avec plusieurs personnages
- **POV Group Sex** - Perspectives POV

### ModÃ¨les LLM
- **Mistral** (via Ollama) - ModÃ¨le de langage polyvalent

> **Note :** Les modÃ¨les sont tÃ©lÃ©chargÃ©s automatiquement au premier dÃ©marrage (~50-70 GB). Vous pouvez ajouter vos propres modÃ¨les via l'interface Civitai Helper.

---

## ğŸŒ AccÃ¨s aux Interfaces

Une fois le container dÃ©marrÃ© :

| Service | URL | Description |
|---------|-----|-------------|
| **SD-Forge-Neo** | http://localhost:7860 | GÃ©nÃ©ration d'images |
| **Open WebUI** | http://localhost:8080 | Chat avec Ollama |
| **Ollama API** | http://localhost:11434 | API Ollama (interne) |

### AccÃ¨s Distant SÃ©curisÃ©

Pour un accÃ¨s depuis l'extÃ©rieur, voir la section **[AccÃ¨s SÃ©curisÃ©](README.md#-accÃ¨s-sÃ©curisÃ©-depuis-lextÃ©rieur)** dans le README principal.

---

## ğŸ› ï¸ Gestion

### Script de Gestion Interactif

```bash
chmod +x manage.sh
./manage.sh
```

Menu avec 16 options :
- âœ… Voir le statut du container
- â–¶ï¸ DÃ©marrer/ArrÃªter/RedÃ©marrer
- ğŸ“‹ Logs en temps rÃ©el
- ğŸ’» Monitoring CPU/GPU
- ğŸ“¦ GÃ©rer les modÃ¨les Ollama
- ğŸ’¾ Backup automatique
- Et plus...

### Commandes Essentielles

```bash
# Voir les logs
docker logs -f ai-container

# RedÃ©marrer le container
docker restart ai-container

# Ã‰tat des services internes
docker exec ai-container supervisorctl status

# TÃ©lÃ©charger un modÃ¨le Ollama
docker exec ai-container ollama pull llama3.3
```

---

## ğŸ› DÃ©pannage

### Container ne dÃ©marre pas
```bash
docker logs ai-container
```

### GPU non dÃ©tectÃ©
```bash
nvidia-smi
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

### Service ne rÃ©pond pas
```bash
docker exec ai-container supervisorctl status
docker exec ai-container supervisorctl restart <service-name>
```

### Tests de Validation
```bash
chmod +x test.sh
./test.sh
```

Pour plus de dÃ©pannage, consultez **[README.md - Section DÃ©pannage](README.md#-dÃ©pannage)**.

---

## ğŸ“¦ Structure du Projet

```
docker-ai-allinone/
â”œâ”€â”€ Dockerfile                    # Image Docker principale
â”œâ”€â”€ docker-compose.yml            # Configuration Docker Compose
â”œâ”€â”€ .dockerignore                 # Optimisation du build
â”œâ”€â”€ .gitignore                    # Fichiers Git exclus
â”‚
â”œâ”€â”€ install.sh                    # Installation automatique
â”œâ”€â”€ manage.sh                     # Gestion interactive
â”œâ”€â”€ test.sh                       # Tests de validation
â”œâ”€â”€ deploy-brev.sh                # DÃ©ploiement Brev.dev
â”œâ”€â”€ deploy-github.sh              # DÃ©ploiement GitHub
â”‚
â”œâ”€â”€ README.md                     # Documentation principale
â”œâ”€â”€ QUICKSTART.md                 # Guide rapide
â”œâ”€â”€ GUIDE_BREV.md                 # Guide Brev.dev
â”œâ”€â”€ NOTES_TECHNIQUES.md           # Configurations avancÃ©es
â””â”€â”€ FICHIERS.md                   # Index des fichiers
```

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. **Fork** le projet
2. CrÃ©ez une branche pour votre fonctionnalitÃ© (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Pushez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une **Pull Request**

### IdÃ©es de Contribution

- Support pour d'autres modÃ¨les Stable Diffusion
- IntÃ©gration de nouveaux LLM
- AmÃ©lioration des performances
- Scripts de dÃ©ploiement pour d'autres plateformes cloud
- Documentation dans d'autres langues

---

## ğŸ“„ License

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- [SD-Forge-Neo](https://github.com/Haoming02/sd-webui-forge-classic) - Interface Stable Diffusion
- [Civitai](https://civitai.com) - HÃ©bergement des modÃ¨les
- [Ollama](https://ollama.com) - Moteur LLM local
- [Open WebUI](https://github.com/open-webui/open-webui) - Interface web moderne

---

## ğŸ“ Support

- **Issues** : [GitHub Issues](https://github.com/VOTRE-USERNAME/docker-ai-allinone/issues)
- **Discussions** : [GitHub Discussions](https://github.com/VOTRE-USERNAME/docker-ai-allinone/discussions)
- **Documentation** : Voir les fichiers `.md` dans le repo

---

## â­ Star History

Si ce projet vous a aidÃ©, n'hÃ©sitez pas Ã  lui donner une â­ sur GitHub !

---

**CrÃ©Ã© avec â¤ï¸ pour la communautÃ© AI/ML**
